# -*- coding: utf-8 -*-
"""TCC_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N1pSmjuSS3_RlWXeFSGZ81q0AFsrdGdL

### Aluno: Ernesto Gurgel Valente Neto
---
# Trabalho de Conclusão de Curso - Artigo Academico

#1.0 PREPARANDO O AMBIENTE E IMPORTANDO AS BIBLIOTECAS

*   IMPORTAR AS BIBLIOTECAS NECESSARIAS PARA ANALISE DE DADOS
*   MONTAR O DRIVE PARA LEITURA DOS DADOS
"""

#Importando as Bibliotecas de Analise de Dados  
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter

from google.colab import drive
drive.mount('/content/drive')

"""TRATAMENTO

*   VERIFICAÇÃO DA BASE DE DADOS
*   VERIFICAÇÃO DE VALORES MISSING


"""

df = pd.read_csv("/content/drive/MyDrive/TCC/Car_Prices.csv")

#Verificando o dataset
df.head()

#Verificando o dataset
len(df)

"""# 2.0 ANALISE DE DADOS"""

#Verificando os tipos de dados
df.info()

#Verificando valores nulos
df.isna().sum()

#Removendo valores nulos
df.drop(columns=["generation_name","Unnamed: 0"],inplace=True)

#Verificando valores removidos
df.isna().sum()

count = (df['year'] < 2002).sum()
print("Valores abaixo do ano 2002: ", count)

#['Diesel' 'CNG' 'Gasoline' 'LPG' 'Hybrid' 'Electric']
count = (df['fuel'] == 'Diesel').sum()
print("Valores abaixo do ano 2002: ", count)

#['Diesel' 'CNG' 'Gasoline' 'LPG' 'Hybrid' 'Electric']
count = (df['fuel'] == 'CNG').sum()
print("Valores abaixo do ano 2002: ", count)

#['Diesel' 'CNG' 'Gasoline' 'LPG' 'Hybrid' 'Electric']
count = (df['fuel'] == 'Gasoline').sum()
print("Valores abaixo do ano 2002: ", count)

#['Diesel' 'CNG' 'Gasoline' 'LPG' 'Hybrid' 'Electric']
count = (df['fuel'] == 'LPG').sum()
print("Valores abaixo do ano 2002: ", count)

#['Diesel' 'CNG' 'Gasoline' 'LPG' 'Hybrid' 'Electric']
count = (df['fuel'] == 'Hybrid').sum()
print("Valores abaixo do ano 2002: ", count)

#['Diesel' 'CNG' 'Gasoline' 'LPG' 'Hybrid' 'Electric']
count = (df['fuel'] == 'Electric').sum()
print("Valores abaixo do ano 2002: ", count)

n = 5
c = Counter(df['mark'])
c.most_common(5)
print ("Marca mais comum: ",c.most_common(5))
print ("Marca: menos comum", c.most_common()[:-n-1:-1])

c = Counter(df['model'])
c.most_common(5)
print ("Modelo mais comum: ",c.most_common(5))
print ("Modelo: menos comum", c.most_common()[:-n-1:-1])

c = Counter(df['year'])
c.most_common(5)
print ("Ano mais comum: ",c.most_common(5))
print ("Ano: menos comum", c.most_common()[:-n-1:-1])

c = Counter(df['vol_engine'])
c.most_common(5)
print ("Motor mais comum: ",c.most_common(5))
print ("Motor mais comum: menos comum", c.most_common()[:-n-1:-1])

c = Counter(df['fuel'])
c.most_common(5)
print ("Combustivel mais comum: ",c.most_common(5))
print ("Combustivel: menos comum", c.most_common()[:-n-1:-1])

c = Counter(df['city'])
c.most_common(5)
print ("Cidade mais comum: ",c.most_common(5))
print ("Cidade: menos comum", c.most_common()[:-n-1:-1])

c = Counter(df['province'])
c.most_common(5)
print ("Estado mais comum: ",c.most_common(5))
print ("Estado: menos comum", c.most_common()[:-n-1:-1])

c = Counter(df['price'])
c.most_common(5)
print ("Preço $: ",c.most_common(5))
print ("Preço $: menos comum", c.most_common()[:-n-1:-1])

"""VERIFICAÇÃO STATISTICA DOS DADOS DA BASE

1.   ANALISE DOS CONJUNTOS DE DADOS
2.   ANALISES ESTATISTICAS E DE DISTRIBUIÇÃO


"""

df.describe()

dfnormal = df.copy()

#Tamanho Total da Base
df.count().sum()

#Verificação da distribuição dos dados de cada tipo
print("Verificação da Distribuição da Marca: ", df['mark'].nunique())
print("Verificação da Distribuição da Modelo: ",df['model'].nunique())
print("Verificação da Distribuição da Ano: ",df['year'].nunique())
print("Verificação da Distribuição da Kilometragem: ",df['mileage'].nunique())
print("Verificação da Distribuição da Mortor: ",df['vol_engine'].nunique())
print("Verificação da Distribuição da Combustivel: ",df['fuel'].nunique())
print("Verificação da Distribuição da Cidade: ",df['city'].nunique())
print("Verificação da Distribuição da Estado: ",df['province'].nunique())
print("Verificação da Distribuição da Preços: ",df['price'].nunique())

print("Modelos de Marcas: ", df["mark"].unique())
print("__________________________________________")
print("Modelos de carros: ", df["model"].unique())
print("__________________________________________")
print("Modelos do Motor: ", df["vol_engine"].unique())
print("__________________________________________")
print("Tipo de Combustivel: ", df["fuel"].unique())
print("__________________________________________")
print("Cidade: ", df["city"].unique())
print("__________________________________________")
print("Estado: ", df["province"].unique())

"""PLOTAGEM DA DISTRIBUIÇÃO DA BASE DE DADOS

1.   OBSERVAÇÃO DOS ATRIBUTOS
2.   ANALISE DE OUTLIERS


"""

plt.figure(figsize=(20,5))
sns.countplot(df["mark"])
plt.show()

sns.set(font_scale=1.4)
df['model'].value_counts().plot(kind='bar', figsize=(300, 20), rot=0)
plt.xlabel("model", labelpad=25)
plt.ylabel("Contagem do model", labelpad=25)
plt.title("Hierarquia dos Modelos", y=1.02);

plt.figure(figsize=(50,10))
sns.countplot(df["year"])
plt.show()

df["mileage_hist"] = pd.cut(df["mileage"],
                           bins=[0., 25000, 50000, 75000, 100000, 2000000.],
                           labels=[1, 2, 3, 4, 5])

df["mileage_hist"].hist();

df["vol_engine"].hist();

plt.figure(figsize=(20,5))
sns.countplot(df["fuel"])
plt.show()

df['city'].value_counts().head(30).plot(kind='barh', figsize=(20,10))

plt.figure(figsize=(60,10))
sns.countplot(df["province"])
plt.show()

df["price_hist"] = pd.cut(df["price"],
                           bins=[0., 5000, 10000, 25000, 100000, 250000, 500000],
                           labels=[1, 2, 3, 4, 5, 6])

df["price_hist"].hist();

"""ANALISE DE OUTILIERS"""

df.boxplot(by ='mark', column =['price'], figsize=(30,10), grid = True)

df.boxplot(by ='model', column =['price'], figsize=(300,25), grid = True)

df.boxplot(by ='year', column =['price'], figsize=(50,10), grid = True)

#Tempo de Execução Muito Longo
df.boxplot(by = 'mileage_hist', column =['price'], figsize=(60,10), grid = True)

df.boxplot(by ='vol_engine', column =['price'], figsize=(450,10), grid = True)

df.boxplot(by ='fuel', column =['price'], figsize=(30,10), grid = True)

df.boxplot(by ='city', column =['price'], figsize=(300,10), grid = True)

df.boxplot(by ='province', column =['price'], figsize=(60,10), grid = True)

"""LEVANTAMENTO DE DADOS RELACIONADOS A VARIAVEL DE ACRECIMO DO VALOR DO VEICULO

1.   Pesquisa de conhecimento, utilizando web para identificar o conhecimento relacionado ao impacto sobre valor do carro.
2.   Graficos corelacionados ao qual indicam acrescimo do valor sob veiculo.

* Analise de informação sobre desvalorização

Os principais fatores que afetam a desvalorização dos ativos adiquiridos pela população são, os modelos, ano, assim como a granularidade da recepção de um local em relação a veiculos semi-novos ou usados. Como também, a quilometragem, acessorios do carro e estado de conservação.


1.   Quilometragem
2.   Versões e equipamentos
3.   Ausência de equipamentos
3.   Estado geral de conservação

* Analise de informação sobre valorização

https://g1.globo.com/economia/noticia/2021/11/16/por-que-os-precos-dos-carros-dispararam-no-mundo.ghtml

https://www.minutoseguros.com.br/blog/alta-de-preco-de-veiculos-entenda-como-isso-impacta-no-valor-do-seguro/

Segundo o modelo de percepção dos fabricantes os motivos dos custos advem da produção dos ativos, aplicando precificação adicional pela marca no mercado, assim como a receptividade do mercado em relação ao veiculo. Outros fatores também seguem;


1.   ICMS
2.   Falta de materiais
3.   Alta demanda
4.   Paralisação de fábricas
5.   Preferência dos usuários por cores de carros
"""

Mark = df.groupby("mark")["price"].mean()

Mark.plot(kind= "bar", figsize=(25,7))

Model = df.groupby("model")["price"].mean()

Model.head(30).plot(kind='barh', figsize=(20,10))

#Acrescimos dos valores por Ano
plt.figure(figsize=(25,7))
sns.lineplot(data=df,x="year",y="price")

#Acrescimos dos valores por mileage
plt.figure(figsize=(25,7))
sns.lineplot(data=df,x="mileage_hist",y="price")

#Acrescimos dos valores por Engine
plt.figure(figsize=(25,7))
sns.lineplot(data=df,x="vol_engine",y="price")

#Acrescimos dos valores por Engine
plt.figure(figsize=(25,7))
sns.lineplot(data=df,x="fuel",y="price")

#Acrescimos dos valores por city
City = df.groupby("city")["price"].mean()
City.head(30).plot(kind='barh', figsize=(20,10))

#Acrescimos dos valores por Engine
plt.figure(figsize=(85,10))
sns.lineplot(data=df,x="province",y="price")

"""ANALISE DO IMPACTO DOS OUTLIERS E O PREÇO"""

def outliers_detector(df):
   q1=df.quantile(0.25)
   q3=df.quantile(0.75)
   variação_interquartil = q3 - q1
   outliers = df[((df<(q1-1.5*variação_interquartil)) | (df>(q3+1.5*variação_interquartil)))]
   return outliers

outliers = outliers_detector(df['price'])
outliers

print("Valor Maximo: ", outliers.max())
print("Valor Médio: ", (outliers.sum()/len(outliers)))
print("Valor Mínimo: ", outliers.min())
totalOut = len(outliers)
print("Total de Outliers: ", totalOut)

baseTotal = df.count().sum()
print('Total da base de dados: ', baseTotal)

#Porcentagem de relação do total de outliers e tamanho do Dataset
print('Outliers representam: ' + str(totalOut/baseTotal) + '% da base de dados')

outliers.hist();

#Distribuição dos outliers
plt.figure(figsize=(25,7))
sns.lineplot(data=outliers)

"""IDENTIFICAÇÃO DOS VALORES E TIPOS MAIS COMUNS DE DADOS"""

c.most_common(5)
print ("Marca: ",c.most_common(5))

c = Counter(df['model'])
c.most_common(5)
print ("Modelo: ",c.most_common(5))

c = Counter(df['year'])
c.most_common(5)
print ("Ano: ",c.most_common(5))

c = Counter(df['vol_engine'])
c.most_common(5)
print ("Motor: ",c.most_common(5))

c = Counter(df['fuel'])
c.most_common(5)
print ("Combustivel: ",c.most_common(5))

c = Counter(df['city'])
c.most_common(5)
print ("Cidade: ",c.most_common(5))

c = Counter(df['province'])
c.most_common(5)
print ("Estado: ",c.most_common(5))

c = Counter(df['price'])
c.most_common(5)
print ("Preço $: ",c.most_common(5))

"""ANALISE DA CORRELAÇÃO

"""

df.corr()

corr = df.corr()
corr.style.background_gradient(cmap='coolwarm')

"""SETANDO UMA BASE DE DADOS SEM OUTLIERS

Testando metodos,
 *     Metodo I: IQR (Intervalo Interquartile)
 *     Metodo II: Metodo Z-Score
"""

#Outliers representam: 0.0095% da base de dados. Decidido por removelos para melhor normalização dos preços retirando valores extremos
#Plot da base atual
df.plot()

df['price'].plot()

#Plot do modelo sem outliers
ndf = df['price']
dfNout = ndf.between(ndf.quantile(.05), ndf.quantile(.95))

ndf[dfNout].plot()

#Total de registros remanescentes
ndf.count()

"""## Metodos I: IQR (Intervalo Interquartile)"""

def outliers_IQR(df, feature):
    Q1 = df[feature].quantile(0.25)
    Q3 = df[feature].quantile(0.75)
    IQR = Q3 - Q1
    limite_superior = Q3 + 1.5 * IQR
    limite_inferior = Q1 - 1.5 * IQR
    return limite_superior, limite_inferior

IQRsuperior, IQRinferior = outliers_IQR(df, "price")
print("Intervalo Superior: ", IQRsuperior)
print("Intervalo Inferior: ", IQRinferior)

df[(df['price'] < IQRinferior) | (df['price'] > IQRsuperior)]

IQR_df = df[(df['price'] > IQRinferior) & (df['price'] < IQRsuperior)]

print("Antigo DataFrame: ", df.count().sum())
print("Novo DataFrame: ", IQR_df.count().sum())

len(IQR_df)

IQR_dfToPlot = IQR_df.copy()

"""## Metodo II: Z-Score"""

def outlier_removal(df, feature):
    limite_superior = df[feature].mean() + 3 * df[feature].std()
    limite_inferior = df[feature].mean() - 3 * df[feature].std()
    return limite_superior, limite_inferior

zsuperior, zinferior = outlier_removal(df, "price")
print("Intervalo Superior Z-Score: ", zsuperior)
print("Intervalo Inferior Z-Score: ", zinferior)

df[(df['price'] < zinferior) | (df['price'] > zsuperior)]

z_df = df[(df['price'] > zinferior) & (df['price'] < zsuperior)]

print("Antigo DataFrame: ", df.count().sum())
print("Novo DataFrame: ", z_df.count().sum())

"""## Comparativo tratamentos Metodo I e Metodo II"""

#RO = Remoção de Outliers 
#Comparativo da analise de remoção dos conjuntos
print("Antigo DataFrame: ", df.count().sum())
print("RO IQR Interquartile removidos: ", df.count().sum() - IQR_df.count().sum())
print("RO Metodo Z-Score removidos: ", df.count().sum() - z_df.count().sum())

df['price'].plot()

IQR_df['price'].plot()

z_df['price'].plot()

"""### PLOT DOS 3 TIPOS DE MODELO SEM TRATAMENTO E TRATAMENTO ZSCORE E IQR"""

dfnormal.corr()

IQR_dfToPlot.corr()

z_df.corr()

"""#3.0 CONCLUSÃO DA ANALISE

__

INDICATIVOS DO DATASET

*   Base de dados apresentada representa dados de 1945 a 2022
*   Dentro do Dataset possuem 23 Marcas diferentes, 328 modelos, 508 motores, 6 tipos de combustivel, 4427 cidades e 9000 preços para veiculos.
*   Os dados em sua pluralidade apresentam boa distribuição heterogena.
*   Dados apresentam conjuntos significativos de outliers apos determinadas datas, indicando principalmente virada do seculo 21.
*   Outliers representam: 0.0095% da base de dados.
*   Tamanho do Dataset: 1.061.343

__

LIMPEZA DA BASE DE DADOS REMOVENDO VALORES NULOS E ANALISE DE REMOÇÃO DE OUTLIERS
*   generation_name, 30085 NULOS.
*   Unnamed, removida coluna de numeração.
*   Antigo DataFrame:  1061343
*   RO IQR Interquartile removidos:  90576
*   RO Metodo Z-Score removidos:  22833

__

INDICATIVOS ANALISE DE DADOS

*   MARCA: Audi, Opel, BMW, Volkswagen, Ford
*   MODELO: Astra, Seria-3, A4, Golf , A6
*   ANO: 2021, 2017, 2018, 2016, 2009
*   MOTOR:1598, 1968, 1995, 1997, 1998
*   COMBUSTIVEL: Gasolina, Diesel, LPG, Hybrido, Eletrico
*   CIDADES: Warszawa, Łódź, Kraków, Wrocław, Poznań
*   ESTADO: Mazowieckie, Śląskie, Wielkopolskie, Małopolskie
*   PREÇO: $$19900, $39900, $29900, $18900, $14900
*   PREÇOS MAIS ALTOS: Mercedes, BMW, Audi, Volvo, Alfa-Romeo

__

INDICATIVOS DA CORRELAÇÃO
*   PREÇO: POR KILOMETRAGEM MENOR
*   PREÇO: POR MELHOR MOTOR
*   PREÇO: POR MARCA MAIOR

Decisão de uso do Dataset, temos:
*   df: Aceitação dos outliers como um modelo de comportamento padrão.
*   IQR_df: devido a método ser muito sensível
a valores extremos, removendo valores que não gostariam que fossem retirados do universo.
*   z_df: remoção de outliers univariados ou seja, valores extremos na distribuição de uma variável específica.

# 4. TEOREMA DOS MODELOS

Modelos a seguir presupostos para uso:


*   Regressao linear, KNN, Percepton Simples, ou modelo-ligado a regressao)
*   Linear Regression, Ridge Regression, Neural Network Regression, Lasso Regression, Decision Tree Regression, Random Forest, KNN Model.

* Será aplicado uma escala de desenvolvimento do modelo para melhor analise e mapeamento do desenvolvimento do melhor algoritimo.

Tipo de analise escolhida: 
O resultado da regressão linear é sempre um número. É utilizada adequadamente quando o dataset apresenta algum tipo de tendência de crescimento/descrescimento constante. A análise de regressão pode ser utilizada para resolver os seguintes tipos de problemas: Determinar quais variáveis explanatórias estão relacionadas à variável dependente. Entender o relacionamento entre as variáveis dependentes e explanatórias. Prever valores desconhecidos da variável dependente.

#TRATAMENTO DA BASE DE DADOS PERMITINDO OUTLIERS
"""

from sklearn.preprocessing import LabelEncoder
dfNormal = df

dfNormal

dfNormal.drop(columns=["mileage_hist","price_hist"],axis=1 ,inplace=True)
dfNormal.drop(columns=["city","province"],axis=1 ,inplace=True)

dfNormal

#Convertendo as variaveis categoricas
LE = LabelEncoder()
LE.fit(dfNormal["mark"])
dfNormal["Mark"]=LE.transform(dfNormal["mark"])

#Convertendo as variaveis categoricas
LE2 = LabelEncoder()
LE2.fit(dfNormal["model"])
dfNormal["Model"]=LE2.transform(dfNormal["model"])

#Convertendo as variaveis categoricas
LE3 = LabelEncoder()
LE3.fit(dfNormal["fuel"])
dfNormal["Fuel"]=LE3.transform(dfNormal["fuel"])

dfNormal.drop(columns=["mark","model","fuel"],axis=1 ,inplace=True )#dropping

dfNormal.head(1)

len(dfNormal)

"""# 5. APLICAÇÃO DOS MODELOS SEM OUTLIERS

"""

import warnings
warnings.filterwarnings("ignore")

"""SEPARAÇÃO DOS DADOS DE TREINO E TESTE E PREPARAÇÃO DOS DADOS


"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor

#Treinamento
from sklearn.model_selection import train_test_split
#O coeficiente de determinação também chamado de pontuação R2 é usado para avaliar o desempenho de um modelo de regressão linear.
from sklearn.metrics import r2_score
from sklearn import linear_model

z_df.head(1)

#Drop para organização e ordenação
z_df.drop(columns=["mileage_hist","price_hist"],axis=1 ,inplace=True)
z_df.drop(columns=["city","province"],axis=1 ,inplace=True)

DTCdf = z_df

DTCdf.head(0)

#Convertendo as variaveis categoricas
LE = LabelEncoder()
LE.fit(DTCdf["mark"])
DTCdf["Mark"]=LE.transform(DTCdf["mark"])

#Convertendo as variaveis categoricas
LE2 = LabelEncoder()
LE2.fit(DTCdf["model"])
DTCdf["Model"]=LE2.transform(DTCdf["model"])

#Convertendo as variaveis categoricas
LE3 = LabelEncoder()
LE3.fit(DTCdf["fuel"])
DTCdf["Fuel"]=LE3.transform(DTCdf["fuel"])

DTCdf.head(1)

DTCdf.drop(columns=["mark","model","fuel"],axis=1 ,inplace=True )#dropping

DTCdf.head(10)

len(DTCdf)

#DEFINIÇÃO DOS DADOS DE TREINO E TESTE
X = DTCdf.drop(columns="price")           
y = DTCdf["price"]

#SEPARAÇÃO DOS DADOS DE TREINO E TESTE
#Se você não especificar o random_state no código, toda vez que você executar (executar) seu código, um novo valor aleatório será gerado e os conjuntos de dados de treinamento e teste terão valores diferentes a cada vez.
#No entanto, se um valor fixo for atribuído como random_state = 0 ou 1 ou 42 ou qualquer outro inteiro, não importa quantas vezes você execute seu código, o resultado será o mesmo, ou seja, os mesmos valores nos conjuntos de dados de treinamento e teste.
#Utilizando valor deterministico para servir de base de comparações
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)

print("X TREINO : ", X_train.shape)
print("X TESTE  : ", X_test.shape)
print("Y TREINO : ", y_train.shape)
print("Y TESTE  : ", y_test.shape)

X

#DEFINIÇÃO DOS DADOS DE TREINO E TESTE SEM TRATAMENTO
X2 = dfNormal.drop(columns="price")           
y2 = dfNormal["price"]

X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.3, random_state=42)

print("X2 TREINO : ", X_train2.shape)
print("X2 TESTE  : ", X_test2.shape)
print("Y2 TREINO : ", y_train2.shape)
print("Y2 TESTE  : ", y_test2.shape)

"""#LINEAR REGRESSION

#### Tratamento de Ouliers
"""

regr = linear_model.LinearRegression()
regr.fit(X_train, y_train)
y_pred = regr.predict(X_test)

print("X-TRAINO E Y-TRAINO PONTUAÇÃO: ", regr.score(X_train,y_train))
print("X-TESTE  E Y-TESTE  PONTUAÇÃO: ", regr.score(X_test,y_test))
print("R2_SCORE  MEDIDA DE AJUSTE DO MODELO: " ,r2_score(y_test,y_pred))

"""### Sem Tratamento de Outliers"""

regr2 = linear_model.LinearRegression()
regr2.fit(X_train2, y_train2)
y_pred2 = regr.predict(X_test2)

print("X-TRAINO E Y-TRAINO PONTUAÇÃO: ", regr2.score(X_train2,y_train2))
print("X-TESTE  E Y-TESTE  PONTUAÇÃO: ", regr2.score(X_test2,y_test2))
print("R2_SCORE  MEDIDA DE AJUSTE DO MODELO: " ,r2_score(y_test2,y_pred2))

"""# DecisionTreeClassifier

#### DADOS SEM OUTLIERS
"""

# using the Decision Tree Regressor Model
DTR=DecisionTreeRegressor()
#TREINAMENTO
DTR.fit(X_train,y_train)

#PONTUAÇÕES DO MODELO
print("X-TREINO E Y-TREINO PONTUAÇÃO : ", DTR.score(X_train,y_train))
print("X-TESTE  E Y-TESTE  PONTUAÇÃO : ", DTR.score(X_test,y_test))

# VALORES ESPERADOS PARA DADOS
y_predDTR=DTR.predict(X_test)
print(" R2_SCORE PONTUAÇÃO MEDIA E ESTATISTICA DO MODELO" ,r2_score(y_test,y_predDTR))

"""#### DADOS C/ OUTLIERS"""

# using the Decision Tree Regressor Model
DTR2=DecisionTreeRegressor()
#TREINAMENTO
DTR2.fit(X_train2,y_train2)

#PONTUAÇÕES DO MODELO
print("X-TREINO E Y-TREINO PONTUAÇÃO : ", DTR2.score(X_train2,y_train2))
print("X-TESTE  E Y-TESTE  PONTUAÇÃO : ", DTR2.score(X_test2,y_test2))

# VALORES ESPERADOS PARA DADOS
y_predDTR2 = DTR2.predict(X_test2)
print(" R2_SCORE PONTUAÇÃO MEDIA E ESTATISTICA DO MODELO" ,r2_score(y_test2,y_predDTR2))

""" # Random Forest Regressor Model S/ OULITERS"""

RFR=RandomForestRegressor()
RFR.fit(X_train,y_train)
y_predRFR =RFR.predict(X_test)

print("X-TREINO E Y-TREINO PONTUAÇÃO : ", RFR.score(X_train,y_train))
print("X-TESTE  E Y-TESTE  PONTUAÇÃO : ", RFR.score(X_test,y_test))
print(" R2_SCORE PONTUAÇÃO MEDIA E ESTATISTICA DO MODELO" ,r2_score(y_test,y_predRFR))

""" # Random Forest Regressor Model C/ OULITERS"""

RFR2 = RandomForestRegressor()
RFR2.fit(X_train2,y_train2)
y_predRFR2 = RFR2.predict(X_test2)

print("X-TREINO E Y-TREINO PONTUAÇÃO : ", RFR2.score(X_train,y_train))
print("X-TESTE  E Y-TESTE  PONTUAÇÃO : ", RFR2.score(X_test,y_test))
print(" R2_SCORE PONTUAÇÃO MEDIA E ESTATISTICA DO MODELO" ,r2_score(y_test2,y_predRFR2))

"""- TERMINAR CADA UM COMO ANALISE JUSTA E DIRETA.
-- CORRELACAO DE PEARSON E MATRIZ DA CORELACAO DE SPEAR
-- MATRIZ DE CONFUSAO
-- ESCOLHER A IMPUTACAO DAS VARIAVEIS CATEGORICAS
-- ANALISAR A CARDINALIDADE DOS ATRIBUTOS E FAZER AGRUPAMENTO OU NAO
-- MEDIR A CORRELACAO
-- METRICAS DE REGRESSAO (UMA OU DUAS).
-- PLOT: X VALORES REAIS, Y VALORES PREDITOS E DIAGNONAL A RETA DE REFERENCIA
"""